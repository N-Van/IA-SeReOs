{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "\n",
    "import cv2\n",
    "\n",
    "script_dir = pathlib.Path('./RDN_segmentation_container/MARS/streamlit_apps/')\n",
    "sys.path.append(str(script_dir))\n",
    "import csv\n",
    "import glob\n",
    "import h5py\n",
    "import math\n",
    "import uuid\n",
    "import json\n",
    "import yaml\n",
    "import torch\n",
    "import base64\n",
    "import random\n",
    "import shutil\n",
    "import pickle\n",
    "import socket\n",
    "import difflib\n",
    "import platform\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "import concurrent.futures\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from PIL import Image, ImageColor\n",
    "from torch import optim\n",
    "from functools import wraps\n",
    "from typing import Callable, Tuple\n",
    "from multiprocessing import cpu_count\n",
    "from multiprocessing.pool import Pool\n",
    "from torch.utils.data import DataLoader\n",
    "from adabelief_pytorch import AdaBelief\n",
    "from datetime import datetime, timedelta\n",
    "from timeit import default_timer as timer\n",
    "from random import shuffle as rand_shuffle\n",
    "from sklearn.utils import shuffle as sk_shuffle\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "\n",
    "\n",
    "import utils.dataprocess as dp\n",
    "from net import UNet_Light_RDN\n",
    "from utils.generate import *\n",
    "from utils.label_utils import *\n",
    "from utils.label_utils import _check_label\n",
    "\n",
    "from utils.train import rdn_train, rdn_val\n",
    "from utils.dataset import HDF52D, load_patches, natural_keys\n",
    "from utils.losses import DomainEnrichLoss, dice_loss, DiceOverlap, Accuracy\n",
    "from streamlit_label_prep import get_patches, get_dirt_bone_patches, random_patches, glob_flat_list, clean_image, _check_label, rescale_label_proper, check_for_match, rescale_intensity, downscale_intensity, read_train_yaml, initiate_cuda, _convert_size, generate_hdf5, generate_patches, _setup_patches, parallelize_ratios, generate_ratios_streamlit_multi, generate_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'image labelisé : 353\n",
      "Nombre d'image non segmentée : 353\n"
     ]
    }
   ],
   "source": [
    "slice_types = [\"tif\", \"png\", \"jpg\", \"jpeg\", \"bmp\", \"dcm\"]\n",
    "segmented_dir = pathlib.Path(\"../../Ressources/data/Training_dataset/Antony/new_labels/\")\n",
    "unsegmented_dir = pathlib.Path(\"../../Ressources/data/Training_dataset/Antony/new_unseg/\")\n",
    "\n",
    "segmented_imgs = glob_flat_list(search_directory=segmented_dir, file_types=slice_types, unique=True)\n",
    "unsegmented_imgs = glob_flat_list(search_directory=unsegmented_dir, file_types=slice_types, unique=True)\n",
    "print(\"Nombre d'image labelisé :\",len(segmented_imgs))\n",
    "print(\"Nombre d'image non segmentée :\",len(unsegmented_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création du dossier d'entrainement pour les images non segmentées\n",
      "Traitement des images non-segmentées...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 353/353 [00:03<00:00, 113.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création du dossier d'entrainement pour les images labelisées\n",
      "Traitement des images labelisées...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 353/353 [00:03<00:00, 111.22it/s]\n"
     ]
    }
   ],
   "source": [
    "unseg_dir = pathlib.Path(\"../../Ressources/data/Training_dataset/Antony/new_unseg_training/\")\n",
    "label_dir = pathlib.Path(\"../../Ressources/data/Training_dataset/Antony/new_labels_training/\")\n",
    "            \n",
    "if not unseg_dir.exists():\n",
    "    print(\"Création du dossier d'entrainement pour les images non segmentées\")\n",
    "    unseg_dir.mkdir()\n",
    "    print(\"Traitement des images non-segmentées...\")\n",
    "\n",
    "    img_count = 0\n",
    "    for i in tqdm(range(len(unsegmented_imgs))):\n",
    "        clean_image(inputFilename=unsegmented_imgs[i], suffix=\"\", out_name=\"\", out_type=\"tif\", out_dir=unseg_dir, to_streamlit=False)\n",
    "        img_count += 1\n",
    "\n",
    "if not label_dir.exists():\n",
    "    print(\"Création du dossier d'entrainement pour les images labelisées\")\n",
    "    label_dir.mkdir()\n",
    "    print(\"Traitement des images labelisées...\")\n",
    "\n",
    "    img_count = 0\n",
    "    for i in tqdm(range(len(segmented_imgs))):\n",
    "        clean_image(inputFilename=segmented_imgs[i], suffix=\"\", out_name=\"\", out_type=\"tif\", out_dir=label_dir, to_streamlit=False)\n",
    "        img_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vérification qu'il y a bien 3 classes dans les images labelisées...\n"
     ]
    }
   ],
   "source": [
    "check_list = label_dir.rglob(\"*.tif\")\n",
    "print(\"Vérification qu'il y a bien 3 classes dans les images labelisées...\")\n",
    "for check in check_list:\n",
    "    checking = sitk.ReadImage(str(check))\n",
    "    checked = _check_label(inputImage=checking, expected_classes=3,to_streamlit=False)\n",
    "    if checked == False:\n",
    "        print(f\"Remise à l'échelle des niveaux de gris de {check} correspondant aux classes (niveaux de gris = 0, 128, and 255...)\")\n",
    "        rescale_label_proper(input_image=checking, input_file_name=check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images non segmentées .tif trouvées : 353\n",
      "Nombre d'images labelisées .tif trouvées : 353\n"
     ]
    }
   ],
   "source": [
    "unsegmented_names = glob.glob(str(unseg_dir.joinpath(\"*.tif\")))\n",
    "print(f\"Nombre d'images non segmentées .tif trouvées : {len(unsegmented_names)}\")\n",
    "\n",
    "segmented_names = glob.glob(str(label_dir.joinpath(\"*.tif\")))\n",
    "print(f\"Nombre d'images labelisées .tif trouvées : {len(segmented_names)}\")\n",
    "\n",
    "match_list = segmented_names\n",
    "unsegmented_file_list = unsegmented_names\n",
    "\n",
    "if len(match_list) != len(unsegmented_file_list):\n",
    "    print(f\"Attention, il n'y a pas le même nombre d'images labelisées ({len(match_list)}) et d'images non segmentée ({len(unsegmented_file_list)}) !!!\")\n",
    "    print(\"Cela peut être dû au fait que l'étape de normalisation a échoué pour une raison quelconque (types de fichiers non pris en charge) ou les dossiers sources ne contiennent pas les images d'écriture. Veuillez les vérifier et réessayer \")\n",
    "\n",
    "match_list = [pathlib.Path(label_name).parts[-1] for label_name in match_list]\n",
    "unsegmented_file_list = [pathlib.Path(unseg_name).parts[-1] for unseg_name in unsegmented_file_list]\n",
    "               \n",
    "#Nous ne voulons prendre en compte que les noms de fichiers qui n'ont pas de correspondance\n",
    "match_list = [label_name for label_name in match_list if label_name not in unsegmented_file_list]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nom des images non segmentées:  ['363_rec0459.tif', '363_rec0459_downscaled.tif', '363_rec0459_rescaled.tif', '366_rec0486.tif', '366_rec0486_downscaled.tif', '366_rec0486_rescaled.tif', 'AF14501414FemurDistu_UnSeg_YM.tif', 'AF14501414FemurDistu_UnSeg_YM_downscaled.tif', 'AF14501414FemurDistu_UnSeg_YM_rescaled.tif', 'AVO74_Hawk_headed_Parrot_x_758.tif', 'AVO74_Hawk_headed_Parrot_x_758_downscaled.tif', 'AVO74_Hawk_headed_Parrot_x_758_rescaled.tif', 'AVO74_Hawk_headed_Parrot_y_780.tif', 'AVO74_Hawk_headed_Parrot_y_780_downscaled.tif', 'AVO74_Hawk_headed_Parrot_y_780_rescaled.tif', 'AVO74_Hawk_headed_Parrot_z_496.tif', 'AVO74_Hawk_headed_Parrot_z_496_downscaled.tif', 'AVO74_Hawk_headed_Parrot_z_496_rescaled.tif', 'BE93TibiaL_UnSeg_ZM.tif', 'BE93TibiaL_UnSeg_ZM_downscaled.tif', 'BE93TibiaL_UnSeg_ZM_rescaled.tif', 'BeliManastirG2Talus_YM.tif', 'BeliManastirG2Talus_YM_downscaled.tif', 'BeliManastirG2Talus_YM_rescaled.tif', 'BeliManastirG2Talus_ZM2.tif', 'BeliManastirG2Talus_ZM2_downscaled.tif', 'BeliManastirG2Talus_ZM2_rescaled.tif', 'BE_106_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_440.tif', 'BE_106_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_440_downscaled.tif', 'BE_106_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_440_rescaled.tif', 'BE_111_Humerus_Prox_L_UnSeg_reoriented_sphereVOI_590.tif', 'BE_111_Humerus_Prox_L_UnSeg_reoriented_sphereVOI_590_downscaled.tif', 'BE_111_Humerus_Prox_L_UnSeg_reoriented_sphereVOI_590_rescaled.tif', 'BE_141A_Femur_Prox_R_UnSeg_reoriented_sphereVOI_432.tif', 'BE_141A_Femur_Prox_R_UnSeg_reoriented_sphereVOI_432_downscaled.tif', 'BE_141A_Femur_Prox_R_UnSeg_reoriented_sphereVOI_432_rescaled.tif', 'BE_33_Humerus_Prox_R_UnSeg_Y_110.tif', 'BE_33_Humerus_Prox_R_UnSeg_Y_110_rescaled.tif', 'BE_37_Humerus_Prox_L_UnSeg_Y_630.tif', 'BE_37_Humerus_Prox_L_UnSeg_Y_630_rescaled.tif', 'BE_69_Humerus_Prox_R_UnSeg_X_786.tif', 'BE_69_Humerus_Prox_R_UnSeg_X_786_rescaled.tif', 'BE_84_Femur_Prox_L_UnSeg_Z_113.tif', 'BE_84_Femur_Prox_L_UnSeg_Z_113_downscaled.tif', 'BE_84_Femur_Prox_L_UnSeg_Z_113_rescaled.tif', 'BE_91_Tibia_Dist_R.tif', 'BE_91_Tibia_Dist_R_downscaled.tif', 'BE_91_Tibia_Dist_R_rescaled.tif', 'BE_93_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_625.tif', 'BE_93_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_625_downscaled.tif', 'BE_93_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_625_rescaled.tif', 'BE_99_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_629.tif', 'BE_99_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_629_rescaled.tif', 'CMN29181HumerusU_UnSeg_XM.tif', 'CMN29181HumerusU_UnSeg_XM_downscaled.tif', 'CMN29181HumerusU_UnSeg_XM_rescaled.tif', 'Dart_Stw311Femur_Prox.tif', 'Dart_Stw311Femur_Prox3.tif', 'Dart_Stw311Femur_Prox3_10.tif', 'Dart_Stw311Femur_Prox3_10_downscaled.tif', 'Dart_Stw311Femur_Prox3_10_rescaled.tif', 'Dart_Stw311Femur_Prox3_downscaled.tif', 'Dart_Stw311Femur_Prox3_rescaled.tif', 'Dart_Stw311Femur_Prox4.tif', 'Dart_Stw311Femur_Prox4_downscaled.tif', 'Dart_Stw311Femur_Prox4_rescaled.tif', 'Dart_Stw311Femur_Prox_downscaled.tif', 'Dart_Stw311Femur_Prox_rescaled.tif', 'Dickson_Mounds_278CalcaneusR_UnSeg_01.tif', 'Dickson_Mounds_278CalcaneusR_UnSeg_01_downscaled.tif', 'Dickson_Mounds_278CalcaneusR_UnSeg_01_rescaled.tif', 'DM_278_Calcaneus_Right_UnSeg.tif', 'DM_278_Calcaneus_Right_UnSeg_downscaled.tif', 'DM_278_Calcaneus_Right_UnSeg_rescaled.tif', 'DM_302_568_Calcaneus_Whole_R0965.tif', 'DM_302_568_Calcaneus_Whole_R0965_downscaled.tif', 'DM_302_568_Calcaneus_Whole_R0965_rescaled.tif', 'DM_Calc_128_L.tif', 'DM_Calc_128_L_downscaled.tif', 'DM_Calc_128_L_rescaled.tif', 'DM_FULL_TIB_065_1572.tif', 'DM_FULL_TIB_065_1572_downscaled.tif', 'DM_FULL_TIB_065_1572_rescaled.tif', 'Dolichotis_patagonum_221358_Humerus_Whole_Slice1662.tif', 'Dolichotis_patagonum_221358_Humerus_Whole_Slice1662_downscaled.tif', 'Dolichotis_patagonum_221358_Humerus_Whole_Slice1662_rescaled.tif', 'Dolichotis_patagonum_221358_Humerus_Whole_Slice250.tif', 'Dolichotis_patagonum_221358_Humerus_Whole_Slice250_downscaled.tif', 'Dolichotis_patagonum_221358_Humerus_Whole_Slice250_rescaled.tif', 'DPC_6139_z254.tif', 'DPC_6139_z254_downscaled.tif', 'DPC_6139_z254_rescaled.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_x299.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_x299_downscaled.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_x299_rescaled.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_x377.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_x377_downscaled.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_x377_rescaled.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_y205.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_y205_downscaled.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_y205_rescaled.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_yz300.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_yz300_downscaled.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_yz300_rescaled.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_z1468.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_z1468_downscaled.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_z1468_rescaled.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_z331.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_z331_downscaled.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_z331_rescaled.tif', 'Hydrochoerus_hydrochaeris_362243_Femur_Whole_xy1555.tif', 'Hydrochoerus_hydrochaeris_362243_Femur_Whole_xy1555_downscaled.tif', 'Hydrochoerus_hydrochaeris_362243_Femur_Whole_xy1555_rescaled.tif', 'Hydrochoerus_hydrochaeris_362243_Femur_Whole_xy366.tif', 'Hydrochoerus_hydrochaeris_362243_Femur_Whole_xy366_downscaled.tif', 'Hydrochoerus_hydrochaeris_362243_Femur_Whole_xy366_rescaled.tif', 'Hydrochoerus_hydrochaeris_362243_Femur_Whole_xz409.tif', 'Hydrochoerus_hydrochaeris_362243_Femur_Whole_xz409_downscaled.tif', 'Hydrochoerus_hydrochaeris_362243_Femur_Whole_xz409_rescaled.tif', 'IlokG17Talus_ZM.tif', 'IlokG17Talus_ZM_downscaled.tif', 'IlokG17Talus_ZM_rescaled.tif', 'IlokKralievicaG24Talus_XM.tif', 'IlokKralievicaG24Talus_XM_downscaled.tif', 'IlokKralievicaG24Talus_XM_rescaled.tif', 'IlokKralievicaG24Talus_YM.tif', 'IlokKralievicaG24Talus_YM_downscaled.tif', 'IlokKralievicaG24Talus_YM_rescaled.tif', 'IlokKralievicaG24Talus_ZM.tif', 'IlokKralievicaG24Talus_ZM_downscaled.tif', 'IlokKralievicaG24Talus_ZM_rescaled.tif', 'Ilok_G23_G23_Talus_Whole_XM.tif', 'Ilok_G23_G23_Talus_Whole_XM_downscaled.tif', 'Ilok_G23_G23_Talus_Whole_XM_rescaled.tif', 'Ilok_G23_G23_Talus_Whole_YM.tif', 'Ilok_G23_G23_Talus_Whole_YM_downscaled.tif', 'Ilok_G23_G23_Talus_Whole_YM_rescaled.tif', 'Ilok_G23_G23_Talus_Whole_ZM.tif', 'Ilok_G23_G23_Talus_Whole_ZM_downscaled.tif', 'Ilok_G23_G23_Talus_Whole_ZM_rescaled.tif', 'JMAF1272FemurU_UnSeg_ZM.tif', 'JMAF1272FemurU_UnSeg_ZM_downscaled.tif', 'JMAF1272FemurU_UnSeg_ZM_rescaled.tif', 'Kerm1065GC7_UnSeg_ZM.tif', 'Kerm1065GC7_UnSeg_ZM_downscaled.tif', 'Kerm1065GC7_UnSeg_ZM_rescaled.tif', 'Kerm1065GHumerusL_UnSeg_ZM.tif', 'Kerm1065GHumerusL_UnSeg_ZM_downscaled.tif', 'Kerm1065GHumerusL_UnSeg_ZM_rescaled.tif', 'Kerm149HumerusL_UnSeg_XM.tif', 'Kerm149HumerusL_UnSeg_XM_downscaled.tif', 'Kerm149HumerusL_UnSeg_XM_rescaled.tif', 'Kerm17C7_UnSeg_ZM.tif', 'Kerm17C7_UnSeg_ZM_downscaled.tif', 'Kerm17C7_UnSeg_ZM_rescaled.tif', 'Kerm226C7_UnSeg_ZM.tif', 'Kerm226C7_UnSeg_ZM_downscaled.tif', 'Kerm226C7_UnSeg_ZM_rescaled.tif', 'Kerm610Femur_UnSeg_ZM.tif', 'Kerm610Femur_UnSeg_ZM_downscaled.tif', 'Kerm610Femur_UnSeg_ZM_rescaled.tif', 'Kerm704Femur_UnSeg_YM.tif', 'Kerm704Femur_UnSeg_YM_downscaled.tif', 'Kerm704Femur_UnSeg_YM_rescaled.tif', 'KermA5HumerusL_UnSeg_ZM.tif', 'KermA5HumerusL_UnSeg_ZM_downscaled.tif', 'KermA5HumerusL_UnSeg_ZM_rescaled.tif', 'KermA5HumerusR_UnSeg_ZM.tif', 'KermA5HumerusR_UnSeg_ZM_downscaled.tif', 'KermA5HumerusR_UnSeg_ZM_rescaled.tif', 'KermA5Tibia_UnSeg_XM.tif', 'KermA5Tibia_UnSeg_XM_downscaled.tif', 'KermA5Tibia_UnSeg_XM_rescaled.tif', 'KermK0Femur_UnSeg_XM.tif', 'KermK0Femur_UnSeg_XM_downscaled.tif', 'KermK0Femur_UnSeg_XM_rescaled.tif', 'KermK0HumerusR_UnSeg_YM.tif', 'KermK0HumerusR_UnSeg_YM_downscaled.tif', 'KermK0HumerusR_UnSeg_YM_rescaled.tif', 'KermK1088AC7_UnSeg.tif', 'KermK1088AC7_UnSeg_downscaled.tif', 'KermK1088AC7_UnSeg_rescaled.tif', 'KermK1088AFemur_UnSeg_ZM.tif', 'KermK1088AFemur_UnSeg_ZM_downscaled.tif', 'KermK1088AFemur_UnSeg_ZM_rescaled.tif', 'KermK1088AHumerusL_UnSeg_YM.tif', 'KermK1088AHumerusL_UnSeg_YM_downscaled.tif', 'KermK1088AHumerusL_UnSeg_YM_rescaled.tif', 'KermK17Femur_UnSeg_XM.tif', 'KermK17Femur_UnSeg_XM_downscaled.tif', 'KermK17Femur_UnSeg_XM_rescaled.tif', 'KermK17HumerusL_UnSeg_ZM.tif', 'KermK17HumerusL_UnSeg_ZM_downscaled.tif', 'KermK17HumerusL_UnSeg_ZM_rescaled.tif', 'KermK204C7_UnSeg_YM.tif', 'KermK204C7_UnSeg_YM_downscaled.tif', 'KermK204C7_UnSeg_YM_rescaled.tif', 'KermK204HumerusR_UnSeg_ZM.tif', 'KermK204HumerusR_UnSeg_ZM_downscaled.tif', 'KermK204HumerusR_UnSeg_ZM_rescaled.tif', 'KermK226HumerusL_UnSeg_ZM.tif', 'KermK226HumerusL_UnSeg_ZM_downscaled.tif', 'KermK226HumerusL_UnSeg_ZM_rescaled.tif', 'KermK235C7_UnSeg_ZM.tif', 'KermK235C7_UnSeg_ZM_downscaled.tif', 'KermK235C7_UnSeg_ZM_rescaled.tif', 'KermK39C7_UnSeg_ZM.tif', 'KermK39C7_UnSeg_ZM_downscaled.tif', 'KermK39C7_UnSeg_ZM_rescaled.tif', 'KermK425AC7_UnSeg_XM.tif', 'KermK425AC7_UnSeg_XM_downscaled.tif', 'KermK425AC7_UnSeg_XM_rescaled.tif', 'KermK425AFemur_UnSeg_ZM.tif', 'KermK425AFemur_UnSeg_ZM_downscaled.tif', 'KermK425AFemur_UnSeg_ZM_rescaled.tif', 'Kerm_XBTB_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_254.tif', 'Kerm_XBTB_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_254_downscaled.tif', 'Kerm_XBTB_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_254_rescaled.tif', 'KrapinaCCAPL_UnSeg_YM.tif', 'KrapinaCCAPL_UnSeg_YM_downscaled.tif', 'KrapinaCCAPL_UnSeg_YM_rescaled.tif', 'KrapinaCSCAPHL_UnSeg_ZM.tif', 'KrapinaCSCAPHL_UnSeg_ZM_downscaled.tif', 'KrapinaCSCAPHL_UnSeg_ZM_rescaled.tif', 'KrapinaHP1PL_UnSeg_YM.tif', 'KrapinaHP1PL_UnSeg_YM_downscaled.tif', 'KrapinaHP1PL_UnSeg_YM_rescaled.tif', 'M12_radius_xy_1015.tif', 'M12_radius_xy_184.tif', 'M12_radius_xy_247.tif', 'M12_radius_xy_282.tif', 'M12_radius_xy_486.tif', 'M12_radius_xy_549.tif', 'M12_radius_xy_634.tif', 'M12_radius_xy_815.tif', 'M12_radius_xz_363.tif', 'M12_radius_xz_467.tif', 'M12_radius_xz_574.tif', 'M12_radius_yz_281.tif', 'M12_radius_yz_470.tif', 'M12_radius_yz_528.tif', 'M12_radius_yz_694.tif', 'M17_femur_xy_1280.tif', 'M17_femur_xy_555.tif', 'M17_femur_xy_831.tif', 'M17_femur_xz_1015.tif', 'M17_femur_xz_1313.tif', 'M17_femur_xz_1535.tif', 'M17_femur_yz_1389.tif', 'M17_femur_yz_1527.tif', 'M17_femur_yz_865.tif', 'MCEU_1_3_64Femur_UnSeg_ZM.tif', 'MCEU_1_3_64Femur_UnSeg_ZM_downscaled.tif', 'MCEU_1_3_64Femur_UnSeg_ZM_rescaled.tif', 'MHCP17_1_8Calc_UnSeg_XM.tif', 'MHCP17_1_8Calc_UnSeg_XM_downscaled.tif', 'MHCP17_1_8Calc_UnSeg_XM_rescaled.tif', 'Microtus_pennsylvanicus_568622_Humerus_Whole_MPSlice480.tif', 'Microtus_pennsylvanicus_568622_Humerus_Whole_MPSlice480_downscaled.tif', 'Microtus_pennsylvanicus_568622_Humerus_Whole_MPSlice480_rescaled.tif', 'MRD_VP1_075_x351.tif', 'MRD_VP1_075_x351_downscaled.tif', 'MRD_VP1_075_x351_rescaled.tif', 'Myocastor_coypus_221349_Humerus_Whole_MCSlice635.tif', 'Myocastor_coypus_221349_Humerus_Whole_MCSlice635_downscaled.tif', 'Myocastor_coypus_221349_Humerus_Whole_MCSlice635_rescaled.tif', 'NF20TalusR_UnSeg_ZM.tif', 'NF20TalusR_UnSeg_ZM_downscaled.tif', 'NF20TalusR_UnSeg_ZM_rescaled.tif', 'NF20TibiaL_UnSeg_ZM.tif', 'NF20TibiaL_UnSeg_ZM_downscaled.tif', 'NF20TibiaL_UnSeg_ZM_rescaled.tif', 'NF_132_821042_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_2.tif', 'NF_132_821042_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_2_downscaled.tif', 'NF_132_821042_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_2_rescaled.tif', 'NF_33_819951_Talus_Whole_R1321.tif', 'NF_33_819951_Talus_Whole_R1321_rescaled.tif', 'NF_50_819996_Humerus_Prox_R_UnSeg_Y_541.tif', 'NF_50_819996_Humerus_Prox_R_UnSeg_Y_541_rescaled.tif', 'NF_819964_FULL_FEM_280001.tif', 'NF_819964_FULL_FEM_280001_downscaled.tif', 'NF_819964_FULL_FEM_280001_rescaled.tif', 'NF_90_820715_Femur_Prox_R_UnSeg_reoriented_sphereVOI_2.tif', 'NF_90_820715_Femur_Prox_R_UnSeg_reoriented_sphereVOI_2_downscaled.tif', 'NF_90_820715_Femur_Prox_R_UnSeg_reoriented_sphereVOI_2_rescaled.tif', 'NMNH_Neofelis_nebulosa_580716_Prox_Hum.tif', 'NMNH_Neofelis_nebulosa_580716_Prox_Hum_downscaled.tif', 'NMNH_Neofelis_nebulosa_580716_Prox_Hum_rescaled.tif', 'NMNH_Neofelis_nebulosa_581891_Prox_Hum.tif', 'NMNH_Neofelis_nebulosa_581891_Prox_Hum_downscaled.tif', 'NMNH_Neofelis_nebulosa_581891_Prox_Hum_rescaled.tif', 'Propithecus_0546.tif', 'Propithecus_0546_downscaled.tif', 'Propithecus_0546_rescaled.tif', 'RADII_NF_LR_DIST_UnSEg.tif', 'RADII_NF_LR_DIST_UnSeg_downscaled.tif', 'RADII_NF_LR_DIST_UnSeg_rescaled.tif', 'Reslice_of_BE_141A_Femur_Prox_R_UnSeg_reoriented_sphereVOI_363.tif', 'Reslice_of_BE_141A_Femur_Prox_R_UnSeg_reoriented_sphereVOI_363_downscaled.tif', 'Reslice_of_BE_141A_Femur_Prox_R_UnSeg_reoriented_sphereVOI_363_rescaled.tif', 'SK82_prox_fem_85kV_100uA.tif', 'SK82_prox_fem_85kV_100uA_downscaled.tif', 'SK82_prox_fem_85kV_100uA_rescaled.tif', 'Skull_13_rec0357.tif', 'Skull_13_rec0357_downscaled.tif', 'Skull_13_rec0357_rescaled.tif', 'Skull_1_rec0422.tif', 'Skull_1_rec0422_downscaled.tif', 'Skull_1_rec0422_rescaled.tif', 'Skull_1_x_512.tif', 'Skull_1_x_512_downscaled.tif', 'Skull_1_x_512_rescaled.tif', 'Skull_1_y_407.tif', 'Skull_1_y_407_downscaled.tif', 'Skull_1_y_407_rescaled.tif', 'StJ_F394_2293_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_300.tif', 'StJ_F394_2293_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_300_downscaled.tif', 'StJ_F394_2293_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_300_rescaled.tif', 'StJ_F704_1238_2787_Femur_Prox_UnSeg_reoriented_sphereVOI_2.tif', 'StJ_F704_1238_2787_Femur_Prox_UnSeg_reoriented_sphereVOI_2_downscaled.tif', 'StJ_F704_1238_2787_Femur_Prox_UnSeg_reoriented_sphereVOI_2_rescaled.tif', 'Tamias_minimus_397142_Humerus_Whole_Slice542.tif', 'Tamias_minimus_397142_Humerus_Whole_Slice542_rescaled.tif', 'TxStateD10FemurU_UnSeg_ZM.tif', 'TxStateD10FemurU_UnSeg_ZM_downscaled.tif', 'TxStateD10FemurU_UnSeg_ZM_rescaled.tif', 'UP_Paglicci_UP_Paglicci_12_Talus_Whole_XM.tif', 'UP_Paglicci_UP_Paglicci_12_Talus_Whole_XM_downscaled.tif', 'UP_Paglicci_UP_Paglicci_12_Talus_Whole_XM_rescaled.tif', 'UP_Paglicci_UP_Paglicci_12_Talus_Whole_YM.tif', 'UP_Paglicci_UP_Paglicci_12_Talus_Whole_YM_downscaled.tif', 'UP_Paglicci_UP_Paglicci_12_Talus_Whole_YM_rescaled.tif', 'UP_Paglicci_UP_Paglicci_12_ZM.tif', 'UP_Paglicci_UP_Paglicci_12_ZM_downscaled.tif', 'UP_Paglicci_UP_Paglicci_12_ZM_rescaled.tif', 'VeliaT286Talus_YM.tif', 'VeliaT286Talus_YM_downscaled.tif', 'VeliaT286Talus_YM_rescaled.tif', 'VeliaT300Talus_UnSeg_XM.tif', 'VeliaT300Talus_UnSeg_XM_downscaled.tif', 'VeliaT300Talus_UnSeg_XM_rescaled.tif', 'VeliaT379Talus_UnSeg_ZM.tif', 'VeliaT379Talus_UnSeg_ZM_downscaled.tif', 'VeliaT379Talus_UnSeg_ZM_rescaled.tif', 'Velia_T442_us2545_Talus_Whole_XM.tif', 'Velia_T442_us2545_Talus_Whole_XM_downscaled.tif', 'Velia_T442_us2545_Talus_Whole_XM_rescaled.tif', 'Velia_T442_us2545_Talus_Whole_YM.tif', 'Velia_T442_us2545_Talus_Whole_YM_downscaled.tif', 'Velia_T442_us2545_Talus_Whole_YM_rescaled.tif', 'Velia_T442_us2545_Talus_Whole_ZM.tif', 'Velia_T442_us2545_Talus_Whole_ZM_downscaled.tif', 'Velia_T442_us2545_Talus_Whole_ZM_rescaled.tif']\n"
     ]
    }
   ],
   "source": [
    "print(\"Nom des images non segmentées: \", unsegmented_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nom des images non labelisées:  ['RADII_NF_LR_DIST_UnSeg.tif', 'VeliaT300Talus_Unseg_XM.tif', 'VeliaT300Talus_Unseg_XM_downscaled.tif', 'VeliaT300Talus_Unseg_XM_rescaled.tif']\n"
     ]
    }
   ],
   "source": [
    "print(\"Nom des images non labelisées: \", match_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vérification du dataset...\n",
      "Aucun fichier mal nommé n'a été trouvé !\n"
     ]
    }
   ],
   "source": [
    "print(\"Vérification du dataset...\")\n",
    "if match_list:\n",
    "    unmatched_labels = {}\n",
    "    for label_name in match_list:\n",
    "        if not unseg_dir.joinpath(label_name).is_file():\n",
    "            file_type_check = glob.glob(str(unseg_dir.joinpath(label_name.rsplit(\".\")[0])))\n",
    "            if len(file_type_check) == 1:\n",
    "                unmatched_labels[str(label_name)] = file_type_check\n",
    "            elif len(file_type_check) > 1:\n",
    "                print(f\"Attention : Plusieurs liens détectés pour {label_name}\")\n",
    "                print(file_type_check)\n",
    "                unmatched_labels[str(label_name)] = file_type_check\n",
    "            else:\n",
    "                possible_match = check_for_match(missing_file=label_name, check_filelist=unsegmented_file_list, to_streamlit=False)\n",
    "                if possible_match == None:\n",
    "                    unmatched_labels[str(label_name)] = [\"None\"]\n",
    "                else:\n",
    "                    unmatched_labels[str(label_name)] = possible_match\n",
    "    if len(unmatched_labels) == 0:\n",
    "        print(\"Aucun fichier mal nommé n'a été trouvé !\")\n",
    "        unmatched_labels = pd.DataFrame()\n",
    "    else:\n",
    "        unmatched_labels = pd.DataFrame.from_dict(unmatched_labels,  orient='index')\n",
    "        unmatched_labels.reset_index(drop=False, inplace=True)\n",
    "        if unmatched_labels.shape[1] > 2:\n",
    "            columns_names = [f\"unsegmented_name_match_{column_num}\" for column_num in unmatched_labels.columns[1:]]\n",
    "            columns_names = [\"label_name\"] + columns_names\n",
    "            unmatched_labels.columns = columns_names\n",
    "        else:\n",
    "            unmatched_labels.columns = [\"label_name\", \"unsegmented_name_match\"]\n",
    "else:\n",
    "    print(\"Aucun fichier mal nommé n'a été trouvé !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Augmentation : \n",
      "Augmentation du nombre de données pour l'entraînement : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/136 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:06<00:00, 21.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouvelles images non-segmentées:  ['363_rec0459.tif', '366_rec0486.tif', 'AF14501414FemurDistu_UnSeg_YM.tif', 'AVO74_Hawk_headed_Parrot_x_758.tif', 'AVO74_Hawk_headed_Parrot_y_780.tif', 'AVO74_Hawk_headed_Parrot_z_496.tif', 'BE93TibiaL_UnSeg_ZM.tif', 'BeliManastirG2Talus_YM.tif', 'BeliManastirG2Talus_ZM2.tif', 'BE_106_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_440.tif', 'BE_111_Humerus_Prox_L_UnSeg_reoriented_sphereVOI_590.tif', 'BE_141A_Femur_Prox_R_UnSeg_reoriented_sphereVOI_432.tif', 'BE_33_Humerus_Prox_R_UnSeg_Y_110.tif', 'BE_37_Humerus_Prox_L_UnSeg_Y_630.tif', 'BE_69_Humerus_Prox_R_UnSeg_X_786.tif', 'BE_84_Femur_Prox_L_UnSeg_Z_113.tif', 'BE_91_Tibia_Dist_R.tif', 'BE_93_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_625.tif', 'BE_99_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_629.tif', 'CMN29181HumerusU_UnSeg_XM.tif', 'Dart_Stw311Femur_Prox.tif', 'Dart_Stw311Femur_Prox3.tif', 'Dart_Stw311Femur_Prox3_10.tif', 'Dart_Stw311Femur_Prox4.tif', 'Dickson_Mounds_278CalcaneusR_UnSeg_01.tif', 'DM_278_Calcaneus_Right_UnSeg.tif', 'DM_302_568_Calcaneus_Whole_R0965.tif', 'DM_Calc_128_L.tif', 'DM_FULL_TIB_065_1572.tif', 'Dolichotis_patagonum_221358_Humerus_Whole_Slice1662.tif', 'Dolichotis_patagonum_221358_Humerus_Whole_Slice250.tif', 'DPC_6139_z254.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_x299.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_x377.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_y205.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_yz300.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_z1468.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_z331.tif', 'Hydrochoerus_hydrochaeris_362243_Femur_Whole_xy1555.tif', 'Hydrochoerus_hydrochaeris_362243_Femur_Whole_xy366.tif', 'Hydrochoerus_hydrochaeris_362243_Femur_Whole_xz409.tif', 'IlokG17Talus_ZM.tif', 'IlokKralievicaG24Talus_XM.tif', 'IlokKralievicaG24Talus_YM.tif', 'IlokKralievicaG24Talus_ZM.tif', 'Ilok_G23_G23_Talus_Whole_XM.tif', 'Ilok_G23_G23_Talus_Whole_YM.tif', 'Ilok_G23_G23_Talus_Whole_ZM.tif', 'JMAF1272FemurU_UnSeg_ZM.tif', 'Kerm1065GC7_UnSeg_ZM.tif', 'Kerm1065GHumerusL_UnSeg_ZM.tif', 'Kerm149HumerusL_UnSeg_XM.tif', 'Kerm17C7_UnSeg_ZM.tif', 'Kerm226C7_UnSeg_ZM.tif', 'Kerm610Femur_UnSeg_ZM.tif', 'Kerm704Femur_UnSeg_YM.tif', 'KermA5HumerusL_UnSeg_ZM.tif', 'KermA5HumerusR_UnSeg_ZM.tif', 'KermA5Tibia_UnSeg_XM.tif', 'KermK0Femur_UnSeg_XM.tif', 'KermK0HumerusR_UnSeg_YM.tif', 'KermK1088AC7_UnSeg.tif', 'KermK1088AFemur_UnSeg_ZM.tif', 'KermK1088AHumerusL_UnSeg_YM.tif', 'KermK17Femur_UnSeg_XM.tif', 'KermK17HumerusL_UnSeg_ZM.tif', 'KermK204C7_UnSeg_YM.tif', 'KermK204HumerusR_UnSeg_ZM.tif', 'KermK226HumerusL_UnSeg_ZM.tif', 'KermK235C7_UnSeg_ZM.tif', 'KermK39C7_UnSeg_ZM.tif', 'KermK425AC7_UnSeg_XM.tif', 'KermK425AFemur_UnSeg_ZM.tif', 'Kerm_XBTB_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_254.tif', 'KrapinaCCAPL_UnSeg_YM.tif', 'KrapinaCSCAPHL_UnSeg_ZM.tif', 'KrapinaHP1PL_UnSeg_YM.tif', 'M12_radius_xy_1015.tif', 'M12_radius_xy_184.tif', 'M12_radius_xy_247.tif', 'M12_radius_xy_282.tif', 'M12_radius_xy_486.tif', 'M12_radius_xy_549.tif', 'M12_radius_xy_634.tif', 'M12_radius_xy_815.tif', 'M12_radius_xz_363.tif', 'M12_radius_xz_467.tif', 'M12_radius_xz_574.tif', 'M12_radius_yz_281.tif', 'M12_radius_yz_470.tif', 'M12_radius_yz_528.tif', 'M12_radius_yz_694.tif', 'M17_femur_xy_1280.tif', 'M17_femur_xy_555.tif', 'M17_femur_xy_831.tif', 'M17_femur_xz_1015.tif', 'M17_femur_xz_1313.tif', 'M17_femur_xz_1535.tif', 'M17_femur_yz_1389.tif', 'M17_femur_yz_1527.tif', 'M17_femur_yz_865.tif', 'MCEU_1_3_64Femur_UnSeg_ZM.tif', 'MHCP17_1_8Calc_UnSeg_XM.tif', 'Microtus_pennsylvanicus_568622_Humerus_Whole_MPSlice480.tif', 'MRD_VP1_075_x351.tif', 'Myocastor_coypus_221349_Humerus_Whole_MCSlice635.tif', 'NF20TalusR_UnSeg_ZM.tif', 'NF20TibiaL_UnSeg_ZM.tif', 'NF_132_821042_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_2.tif', 'NF_33_819951_Talus_Whole_R1321.tif', 'NF_50_819996_Humerus_Prox_R_UnSeg_Y_541.tif', 'NF_819964_FULL_FEM_280001.tif', 'NF_90_820715_Femur_Prox_R_UnSeg_reoriented_sphereVOI_2.tif', 'NMNH_Neofelis_nebulosa_580716_Prox_Hum.tif', 'NMNH_Neofelis_nebulosa_581891_Prox_Hum.tif', 'Propithecus_0546.tif', 'RADII_NF_LR_DIST_UnSEg.tif', 'Reslice_of_BE_141A_Femur_Prox_R_UnSeg_reoriented_sphereVOI_363.tif', 'SK82_prox_fem_85kV_100uA.tif', 'Skull_13_rec0357.tif', 'Skull_1_rec0422.tif', 'Skull_1_x_512.tif', 'Skull_1_y_407.tif', 'StJ_F394_2293_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_300.tif', 'StJ_F704_1238_2787_Femur_Prox_UnSeg_reoriented_sphereVOI_2.tif', 'Tamias_minimus_397142_Humerus_Whole_Slice542.tif', 'TxStateD10FemurU_UnSeg_ZM.tif', 'UP_Paglicci_UP_Paglicci_12_Talus_Whole_XM.tif', 'UP_Paglicci_UP_Paglicci_12_Talus_Whole_YM.tif', 'UP_Paglicci_UP_Paglicci_12_ZM.tif', 'VeliaT286Talus_YM.tif', 'VeliaT300Talus_UnSeg_XM.tif', 'VeliaT379Talus_UnSeg_ZM.tif', 'Velia_T442_us2545_Talus_Whole_XM.tif', 'Velia_T442_us2545_Talus_Whole_YM.tif', 'Velia_T442_us2545_Talus_Whole_ZM.tif']\n",
      "Nouvelles images labelisées:  ['363_rec0459.tif', '366_rec0486.tif', 'AF14501414FemurDistu_UnSeg_YM.tif', 'AVO74_Hawk_headed_Parrot_x_758.tif', 'AVO74_Hawk_headed_Parrot_y_780.tif', 'AVO74_Hawk_headed_Parrot_z_496.tif', 'BE93TibiaL_UnSeg_ZM.tif', 'BeliManastirG2Talus_YM.tif', 'BeliManastirG2Talus_ZM2.tif', 'BE_106_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_440.tif', 'BE_111_Humerus_Prox_L_UnSeg_reoriented_sphereVOI_590.tif', 'BE_141A_Femur_Prox_R_UnSeg_reoriented_sphereVOI_432.tif', 'BE_33_Humerus_Prox_R_UnSeg_Y_110.tif', 'BE_37_Humerus_Prox_L_UnSeg_Y_630.tif', 'BE_69_Humerus_Prox_R_UnSeg_X_786.tif', 'BE_84_Femur_Prox_L_UnSeg_Z_113.tif', 'BE_91_Tibia_Dist_R.tif', 'BE_93_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_625.tif', 'BE_99_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_629.tif', 'CMN29181HumerusU_UnSeg_XM.tif', 'Dart_Stw311Femur_Prox.tif', 'Dart_Stw311Femur_Prox3.tif', 'Dart_Stw311Femur_Prox3_10.tif', 'Dart_Stw311Femur_Prox4.tif', 'Dickson_Mounds_278CalcaneusR_UnSeg_01.tif', 'DM_278_Calcaneus_Right_UnSeg.tif', 'DM_302_568_Calcaneus_Whole_R0965.tif', 'DM_Calc_128_L.tif', 'DM_FULL_TIB_065_1572.tif', 'Dolichotis_patagonum_221358_Humerus_Whole_Slice1662.tif', 'Dolichotis_patagonum_221358_Humerus_Whole_Slice250.tif', 'DPC_6139_z254.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_x299.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_x377.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_y205.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_yz300.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_z1468.tif', 'Hydrochoerus_hydrochaeris_155412_Femur_Whole_z331.tif', 'Hydrochoerus_hydrochaeris_362243_Femur_Whole_xy1555.tif', 'Hydrochoerus_hydrochaeris_362243_Femur_Whole_xy366.tif', 'Hydrochoerus_hydrochaeris_362243_Femur_Whole_xz409.tif', 'IlokG17Talus_ZM.tif', 'IlokKralievicaG24Talus_XM.tif', 'IlokKralievicaG24Talus_YM.tif', 'IlokKralievicaG24Talus_ZM.tif', 'Ilok_G23_G23_Talus_Whole_XM.tif', 'Ilok_G23_G23_Talus_Whole_YM.tif', 'Ilok_G23_G23_Talus_Whole_ZM.tif', 'JMAF1272FemurU_UnSeg_ZM.tif', 'Kerm1065GC7_UnSeg_ZM.tif', 'Kerm1065GHumerusL_UnSeg_ZM.tif', 'Kerm149HumerusL_UnSeg_XM.tif', 'Kerm17C7_UnSeg_ZM.tif', 'Kerm226C7_UnSeg_ZM.tif', 'Kerm610Femur_UnSeg_ZM.tif', 'Kerm704Femur_UnSeg_YM.tif', 'KermA5HumerusL_UnSeg_ZM.tif', 'KermA5HumerusR_UnSeg_ZM.tif', 'KermA5Tibia_UnSeg_XM.tif', 'KermK0Femur_UnSeg_XM.tif', 'KermK0HumerusR_UnSeg_YM.tif', 'KermK1088AC7_UnSeg.tif', 'KermK1088AFemur_UnSeg_ZM.tif', 'KermK1088AHumerusL_UnSeg_YM.tif', 'KermK17Femur_UnSeg_XM.tif', 'KermK17HumerusL_UnSeg_ZM.tif', 'KermK204C7_UnSeg_YM.tif', 'KermK204HumerusR_UnSeg_ZM.tif', 'KermK226HumerusL_UnSeg_ZM.tif', 'KermK235C7_UnSeg_ZM.tif', 'KermK39C7_UnSeg_ZM.tif', 'KermK425AC7_UnSeg_XM.tif', 'KermK425AFemur_UnSeg_ZM.tif', 'Kerm_XBTB_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_254.tif', 'KrapinaCCAPL_UnSeg_YM.tif', 'KrapinaCSCAPHL_UnSeg_ZM.tif', 'KrapinaHP1PL_UnSeg_YM.tif', 'M12_radius_xy_1015.tif', 'M12_radius_xy_184.tif', 'M12_radius_xy_247.tif', 'M12_radius_xy_282.tif', 'M12_radius_xy_486.tif', 'M12_radius_xy_549.tif', 'M12_radius_xy_634.tif', 'M12_radius_xy_815.tif', 'M12_radius_xz_363.tif', 'M12_radius_xz_467.tif', 'M12_radius_xz_574.tif', 'M12_radius_yz_281.tif', 'M12_radius_yz_470.tif', 'M12_radius_yz_528.tif', 'M12_radius_yz_694.tif', 'M17_femur_xy_1280.tif', 'M17_femur_xy_555.tif', 'M17_femur_xy_831.tif', 'M17_femur_xz_1015.tif', 'M17_femur_xz_1313.tif', 'M17_femur_xz_1535.tif', 'M17_femur_yz_1389.tif', 'M17_femur_yz_1527.tif', 'M17_femur_yz_865.tif', 'MCEU_1_3_64Femur_UnSeg_ZM.tif', 'MHCP17_1_8Calc_UnSeg_XM.tif', 'Microtus_pennsylvanicus_568622_Humerus_Whole_MPSlice480.tif', 'MRD_VP1_075_x351.tif', 'Myocastor_coypus_221349_Humerus_Whole_MCSlice635.tif', 'NF20TalusR_UnSeg_ZM.tif', 'NF20TibiaL_UnSeg_ZM.tif', 'NF_132_821042_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_2.tif', 'NF_33_819951_Talus_Whole_R1321.tif', 'NF_50_819996_Humerus_Prox_R_UnSeg_Y_541.tif', 'NF_819964_FULL_FEM_280001.tif', 'NF_90_820715_Femur_Prox_R_UnSeg_reoriented_sphereVOI_2.tif', 'NMNH_Neofelis_nebulosa_580716_Prox_Hum.tif', 'NMNH_Neofelis_nebulosa_581891_Prox_Hum.tif', 'Propithecus_0546.tif', 'RADII_NF_LR_DIST_UnSeg.tif', 'Reslice_of_BE_141A_Femur_Prox_R_UnSeg_reoriented_sphereVOI_363.tif', 'SK82_prox_fem_85kV_100uA.tif', 'Skull_13_rec0357.tif', 'Skull_1_rec0422.tif', 'Skull_1_x_512.tif', 'Skull_1_y_407.tif', 'StJ_F394_2293_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_300.tif', 'StJ_F704_1238_2787_Femur_Prox_UnSeg_reoriented_sphereVOI_2.tif', 'Tamias_minimus_397142_Humerus_Whole_Slice542.tif', 'TxStateD10FemurU_UnSeg_ZM.tif', 'UP_Paglicci_UP_Paglicci_12_Talus_Whole_XM.tif', 'UP_Paglicci_UP_Paglicci_12_Talus_Whole_YM.tif', 'UP_Paglicci_UP_Paglicci_12_ZM.tif', 'VeliaT286Talus_YM.tif', 'VeliaT300Talus_Unseg_XM.tif', 'VeliaT379Talus_UnSeg_ZM.tif', 'Velia_T442_us2545_Talus_Whole_XM.tif', 'Velia_T442_us2545_Talus_Whole_YM.tif', 'Velia_T442_us2545_Talus_Whole_ZM.tif']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Augmentation : \")\n",
    "print(\"Augmentation du nombre de données pour l'entraînement : \")\n",
    "\n",
    "training_list = [item.name for item in unseg_dir.rglob(\"*.tif\")]\n",
    "training_list = [item for item in training_list if \"_rescaled.tif\" not in item]\n",
    "training_list = [item for item in training_list if \"_downscaled.tif\" not in item]\n",
    "\n",
    "\n",
    "label_list = [item.name for item in label_dir.rglob(\"*.tif\")]\n",
    "label_list = [item for item in label_list if \"_rescaled.tif\" not in item]\n",
    "label_list = [item for item in label_list if \"_downscaled.tif\" not in item]\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(training_list))):\n",
    "    up_check = training_list[i].replace(\".tif\", \"_rescaled.tif\")\n",
    "    down_check = training_list[i].replace(\".tif\", \"_downscaled.tif\")\n",
    "    out_dir = unseg_dir\n",
    "\n",
    "    if not unseg_dir.joinpath(up_check).exists():\n",
    "        rescale_intensity(inputFilename=out_dir.joinpath(training_list[i]), writeOut=True, file_type=\"tif\", outDir=out_dir)\n",
    "        shutil.copy(str(label_dir.joinpath(training_list[i])), str(label_dir.joinpath(up_check)))\n",
    "\n",
    "    if not unseg_dir.joinpath(down_check).exists():\n",
    "        downscale_intensity(inputFilename=out_dir.joinpath(training_list[i]), downscale_value=75, writeOut=True, file_type=\"tif\", outDir=out_dir)\n",
    "        shutil.copy(str(label_dir.joinpath(training_list[i])), str(label_dir.joinpath(down_check)))\n",
    "\n",
    "print(\"Nouvelles images non-segmentées: \",training_list)\n",
    "print(\"Nouvelles images labelisées: \",label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU trouvé !\n",
      "GPU réglé sur le numéro de l'appareil 0: Quadro RTX 5000 ayant 16.0 GB de VRAM\n",
      "Training data save path: ..\\..\\Ressources\\data\\Training_dataset\\data\n",
      "New models will be saved to: ..\\..\\Ressources\\data\\Training_dataset\\data\\new_model\n"
     ]
    }
   ],
   "source": [
    "data_path = unseg_dir.parent.parent.joinpath(\"data\")\n",
    "train_yaml = str(script_dir.joinpath(\"yaml\").joinpath(\"train.yaml\"))\n",
    "test_yaml = str(script_dir.joinpath(\"yaml\").joinpath(\"test.yaml\"))\n",
    "new_models_path = data_path.joinpath(\"new_model\")\n",
    "\n",
    "\n",
    "optimizer = \"Adam\"\n",
    "\n",
    "train_from_yaml = False\n",
    "\n",
    "if train_from_yaml and script_dir.joinpath(\"yaml\").joinpath(\"train.yaml\").exists() and script_dir.joinpath(\"yaml\").joinpath(\"test.yaml\").exist:\n",
    "    #Lecture les informations yaml par défaut\n",
    "    train_yaml_file = read_train_yaml(yaml_file=train_yaml)\n",
    "    test_yaml_file = read_train_yaml(yaml_file=test_yaml)\n",
    "\n",
    "    #Grab the information from the default yamls.\n",
    "    previous_batch = train_yaml_file[\"data_loader\"][\"batch_size\"]\n",
    "    previous_period = train_yaml_file[\"period\"]\n",
    "    previous_epoch = train_yaml_file[\"train_param\"][\"Epoch\"]\n",
    "    previous_learning_rate = train_yaml_file[\"optimizer\"][\"lr\"]\n",
    "    previous_weight_decay = train_yaml_file[\"optimizer\"][\"weight_decay\"]\n",
    "\n",
    "    \n",
    "    batch_size = int(previous_batch)\n",
    "    period_size = int(previous_period)\n",
    "    weight_decay = float(previous_weight_decay)\n",
    "    epsilon = 10**(-8)\n",
    "    epochs_num = int(previous_epoch)\n",
    "    learning_rate = float(previous_learning_rate)\n",
    "    \n",
    "else:\n",
    "    batch_size = 32\n",
    "    period_size = 8\n",
    "    weight_decay = 0.1\n",
    "    epsilon = 10**(-8)\n",
    "    epochs_num = 60\n",
    "    learning_rate = 10**(-3)\n",
    "\n",
    "\n",
    "#Obtention le périphérique GPU\n",
    "if torch.cuda.is_available() and torch.cuda.device_count() >= 1:\n",
    "    use_gpu = 0\n",
    "    print(\"GPU trouvé !\")\n",
    "    torch.cuda.set_device(use_gpu)\n",
    "    cuda_mem = int(torch.cuda.get_device_properties(device=use_gpu).total_memory)\n",
    "    cuda_mem = list(_convert_size(sizeBytes=cuda_mem))\n",
    "    print(f\"GPU réglé sur le numéro de l'appareil {use_gpu}: {torch.cuda.get_device_properties(device=use_gpu).name} ayant {cuda_mem[0]} de VRAM\")\n",
    "else:\n",
    "    print(\"Pas de GPU !\")\n",
    "\n",
    "print(f\"Training data save path: {data_path}\")\n",
    "print(f\"New models will be saved to: {new_models_path}\")\n",
    "\n",
    "\n",
    "train_from_previous = False\n",
    "\n",
    "if train_from_previous:\n",
    "    previous_model =  pathlib.Path(\"Chemin vers le modèle\")\n",
    "    pre_trained = torch.load(previous_model, map_location=f'cuda:{int(use_gpu)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Save the training parameters in a YAML file\")\n",
    "\n",
    "# if not data_path.exists():\n",
    "#     data_path.mkdir()\n",
    "\n",
    "# if train_from_previous:\n",
    "#     pretrained_path = data_path.joinpath(\"pretrained_model\")\n",
    "#     if not pretrained_path.exists():\n",
    "#         pretrained_path.mkdir()\n",
    "#     model_name = str(pretrained_path.joinpath(\"pretrained_model.pth\").as_posix())\n",
    "#     torch.save(pre_trained, str(model_name))\n",
    "#     train_yaml_file[\"model\"][\"if_pre_train\"] = \"true\"\n",
    "#     train_yaml_file[\"model\"][\"path\"] = str(model_name)\n",
    "# else:\n",
    "#     train_yaml_file[\"model\"][\"if_pre_train\"] = \"false\"\n",
    "#     train_yaml_file[\"model\"][\"path\"] = None\n",
    "\n",
    "# #GPU device index\n",
    "# train_yaml_file[\"gpu_config\"][\"gpu_name\"] = int(use_gpu)\n",
    "\n",
    "# #Loops\n",
    "# train_yaml_file[\"data_loader\"][\"batch_size\"] = int(batch_size)\n",
    "# if period_size:\n",
    "#     train_yaml_file[\"period\"] = int(period_size)\n",
    "# else:\n",
    "#     train_yaml_file[\"period\"] = None\n",
    "# train_yaml_file[\"train_param\"][\"Epoch\"] = int(epochs_num)\n",
    "\n",
    "# #Optimizer paramters\n",
    "# train_yaml_file[\"optimizer\"][\"method\"] = f'{optimizer}'\n",
    "# train_yaml_file[\"optimizer\"][\"lr\"] = float(learning_rate)\n",
    "# if optimizer == \"AdaBelief\":\n",
    "#     train_yaml_file[\"optimizer\"][\"epsilon\"] = epsilon\n",
    "#     train_yaml_file[\"optimizer\"][\"weight_decay\"] = \"false\"\n",
    "# else:\n",
    "#     train_yaml_file[\"optimizer\"][\"weight_decay\"] = float(weight_decay)\n",
    "\n",
    "# #Data path\n",
    "# train_yaml_file[\"path\"][\"data_path\"] = str(data_path.joinpath(\"dataset.hdf5\").as_posix())\n",
    "# train_yaml_file[\"path\"][\"save_path\"] = str(new_models_path.as_posix())\n",
    "\n",
    "# #CSV path\n",
    "# train_yaml_file[\"csv_path\"][\"train\"] = str(data_path.joinpath(\"patches.csv\").as_posix())\n",
    "# train_yaml_file[\"csv_path\"][\"val\"] = str(data_path.joinpath(\"val.csv\").as_posix())\n",
    "# train_yaml_file[\"csv_path\"][\"ratios\"] = str(data_path.joinpath(\"ratios.csv\").as_posix())\n",
    "\n",
    "# #Test yaml\n",
    "# test_yaml_file[\"gpu_config\"][\"gpu_name\"] = int(state.use_gpu)\n",
    "# test_yaml_file[\"path\"][\"data_path\"] = str(data_path.joinpath(\"dataset.hdf5\").as_posix())\n",
    "# test_yaml_file[\"model\"][\"path\"] = str(new_models_path.as_posix())\n",
    "\n",
    "# test_yaml_file[\"csv_path\"][\"val\"] = str(data_path.joinpath(\"val.csv\").as_posix())\n",
    "\n",
    "# new_yaml_path = data_path.joinpath(\"yaml\")\n",
    "# new_train_yaml_name = new_yaml_path.joinpath(\"train.yaml\")\n",
    "# new_test_yaml_name = new_yaml_path.joinpath(\"test.yaml\")\n",
    "# if not new_yaml_path.exists():\n",
    "#     new_yaml_path.mkdir()\n",
    "\n",
    "# with open(str(new_train_yaml_name), 'w') as f:\n",
    "#     yaml.dump(train_yaml_file, f)\n",
    "#     new_train_yaml_name = new_train_yaml_name\n",
    "\n",
    "# with open(str(new_test_yaml_name), 'w') as f:\n",
    "#     yaml.dump(test_yaml_file, f)\n",
    "#     new_test_yaml_name = new_test_yaml_name\n",
    "    \n",
    "# print(f\"Les paramètres d'entraînement et de validation ont été enregistrés : {new_yaml_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize data\n",
      "Répertoire des données d'entraînement: ../../Ressources/data/Training_dataset/Antony/new_unseg_training\n",
      "Répertoire des données labelisées d'entraînement: ../../Ressources/data/Training_dataset/Antony/new_labels_training\n",
      "Répertoire des données labelisées d'entraînement: ../../Ressources/data/Training_dataset/Antony/new_unseg_training/dataset.hdf5\n",
      "Unable to find a match for BE_33_Humerus_Prox_R_UnSeg_Y_110_downscaled. Please check if the cases, underscores, etc. match.\n",
      "Unable to find a match for BE_37_Humerus_Prox_L_UnSeg_Y_630_downscaled. Please check if the cases, underscores, etc. match.\n",
      "Unable to find a match for BE_69_Humerus_Prox_R_UnSeg_X_786_downscaled. Please check if the cases, underscores, etc. match.\n",
      "Unable to find a match for BE_99_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_629_downscaled. Please check if the cases, underscores, etc. match.\n",
      "Unable to find a match for NF_33_819951_Talus_Whole_R1321_downscaled. Please check if the cases, underscores, etc. match.\n",
      "Unable to find a match for NF_50_819996_Humerus_Prox_R_UnSeg_Y_541_downscaled. Please check if the cases, underscores, etc. match.\n",
      "Unable to find a match for Tamias_minimus_397142_Humerus_Whole_Slice542_downscaled. Please check if the cases, underscores, etc. match.\n",
      "Unable to find a match for VeliaT300Talus_Unseg_XM. Please check if the cases, underscores, etc. match.\n",
      "Unable to find a match for VeliaT300Talus_Unseg_XM_downscaled. Please check if the cases, underscores, etc. match.\n",
      "Unable to find a match for VeliaT300Talus_Unseg_XM_rescaled. Please check if the cases, underscores, etc. match.\n",
      "../../Ressources/data/Training_dataset/Antony/new_unseg_training/dataset.hdf5\n",
      "Validating with 119 images:\n",
      "\n",
      "M17_femur_xy_555\n",
      "\n",
      "M12_radius_xz_363_downscaled\n",
      "\n",
      "BeliManastirG2Talus_ZM2_downscaled\n",
      "\n",
      "M17_femur_yz_865_rescaled\n",
      "\n",
      "Dart_Stw311Femur_Prox_rescaled\n",
      "\n",
      "Hydrochoerus_hydrochaeris_155412_Femur_Whole_y205_rescaled\n",
      "\n",
      "Microtus_pennsylvanicus_568622_Humerus_Whole_MPSlice480_rescaled\n",
      "\n",
      "CMN29181HumerusU_UnSeg_XM_downscaled\n",
      "\n",
      "NF_819964_FULL_FEM_280001_downscaled\n",
      "\n",
      "Hydrochoerus_hydrochaeris_155412_Femur_Whole_z1468_downscaled\n",
      "\n",
      "M12_radius_yz_528\n",
      "\n",
      "MCEU_1_3_64Femur_UnSeg_ZM_downscaled\n",
      "\n",
      "M17_femur_yz_865_downscaled\n",
      "\n",
      "BE93TibiaL_UnSeg_ZM\n",
      "\n",
      "BE_84_Femur_Prox_L_UnSeg_Z_113_rescaled\n",
      "\n",
      "NF_50_819996_Humerus_Prox_R_UnSeg_Y_541\n",
      "\n",
      "BE_33_Humerus_Prox_R_UnSeg_Y_110_rescaled\n",
      "\n",
      "M17_femur_xz_1313_downscaled\n",
      "\n",
      "KrapinaHP1PL_UnSeg_YM\n",
      "\n",
      "KermK425AC7_UnSeg_XM_downscaled\n",
      "\n",
      "Dart_Stw311Femur_Prox3_10_rescaled\n",
      "\n",
      "Skull_1_rec0422_rescaled\n",
      "\n",
      "Propithecus_0546_downscaled\n",
      "\n",
      "M12_radius_xy_486_downscaled\n",
      "\n",
      "NF_819964_FULL_FEM_280001\n",
      "\n",
      "KermK39C7_UnSeg_ZM_downscaled\n",
      "\n",
      "Hydrochoerus_hydrochaeris_155412_Femur_Whole_z331_rescaled\n",
      "\n",
      "KrapinaCSCAPHL_UnSeg_ZM_rescaled\n",
      "\n",
      "BE_84_Femur_Prox_L_UnSeg_Z_113_downscaled\n",
      "\n",
      "Dolichotis_patagonum_221358_Humerus_Whole_Slice250\n",
      "\n",
      "BeliManastirG2Talus_ZM2\n",
      "\n",
      "KermA5HumerusL_UnSeg_ZM_rescaled\n",
      "\n",
      "NMNH_Neofelis_nebulosa_580716_Prox_Hum_downscaled\n",
      "\n",
      "Kerm610Femur_UnSeg_ZM_rescaled\n",
      "\n",
      "KermK0Femur_UnSeg_XM_rescaled\n",
      "\n",
      "KermK235C7_UnSeg_ZM_rescaled\n",
      "\n",
      "Dart_Stw311Femur_Prox3_10_downscaled\n",
      "\n",
      "Myocastor_coypus_221349_Humerus_Whole_MCSlice635_downscaled\n",
      "\n",
      "IlokKralievicaG24Talus_XM\n",
      "\n",
      "Dart_Stw311Femur_Prox_downscaled\n",
      "\n",
      "AVO74_Hawk_headed_Parrot_z_496_rescaled\n",
      "\n",
      "363_rec0459_downscaled\n",
      "\n",
      "Kerm226C7_UnSeg_ZM\n",
      "\n",
      "Hydrochoerus_hydrochaeris_155412_Femur_Whole_x299\n",
      "\n",
      "M12_radius_yz_470_rescaled\n",
      "\n",
      "Kerm1065GHumerusL_UnSeg_ZM_rescaled\n",
      "\n",
      "NMNH_Neofelis_nebulosa_580716_Prox_Hum\n",
      "\n",
      "KermK204C7_UnSeg_YM_downscaled\n",
      "\n",
      "KermK17HumerusL_UnSeg_ZM_rescaled\n",
      "\n",
      "M12_radius_yz_281_downscaled\n",
      "\n",
      "KrapinaHP1PL_UnSeg_YM_rescaled\n",
      "\n",
      "MRD_VP1_075_x351_downscaled\n",
      "\n",
      "M12_radius_xy_1015_rescaled\n",
      "\n",
      "BE_106_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_440_downscaled\n",
      "\n",
      "NF_90_820715_Femur_Prox_R_UnSeg_reoriented_sphereVOI_2_rescaled\n",
      "\n",
      "Reslice_of_BE_141A_Femur_Prox_R_UnSeg_reoriented_sphereVOI_363_downscaled\n",
      "\n",
      "Velia_T442_us2545_Talus_Whole_YM\n",
      "\n",
      "Ilok_G23_G23_Talus_Whole_YM_downscaled\n",
      "\n",
      "KermK204C7_UnSeg_YM_rescaled\n",
      "\n",
      "BE_99_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_629_rescaled\n",
      "\n",
      "M17_femur_xy_831_downscaled\n",
      "\n",
      "Kerm1065GC7_UnSeg_ZM\n",
      "\n",
      "VeliaT286Talus_YM_downscaled\n",
      "\n",
      "DM_302_568_Calcaneus_Whole_R0965_rescaled\n",
      "\n",
      "Hydrochoerus_hydrochaeris_155412_Femur_Whole_z1468\n",
      "\n",
      "KermK425AC7_UnSeg_XM_rescaled\n",
      "\n",
      "M17_femur_xz_1015_downscaled\n",
      "\n",
      "KrapinaCCAPL_UnSeg_YM\n",
      "\n",
      "BE_91_Tibia_Dist_R\n",
      "\n",
      "AVO74_Hawk_headed_Parrot_y_780_rescaled\n",
      "\n",
      "UP_Paglicci_UP_Paglicci_12_ZM_downscaled\n",
      "\n",
      "Dolichotis_patagonum_221358_Humerus_Whole_Slice250_downscaled\n",
      "\n",
      "M17_femur_yz_1527_rescaled\n",
      "\n",
      "M12_radius_yz_694_downscaled\n",
      "\n",
      "KermK226HumerusL_UnSeg_ZM_downscaled\n",
      "\n",
      "AVO74_Hawk_headed_Parrot_z_496\n",
      "\n",
      "BE_111_Humerus_Prox_L_UnSeg_reoriented_sphereVOI_590_rescaled\n",
      "\n",
      "Kerm704Femur_UnSeg_YM_rescaled\n",
      "\n",
      "KermA5Tibia_UnSeg_XM_downscaled\n",
      "\n",
      "Kerm704Femur_UnSeg_YM_downscaled\n",
      "\n",
      "BE_141A_Femur_Prox_R_UnSeg_reoriented_sphereVOI_432\n",
      "\n",
      "Dart_Stw311Femur_Prox4\n",
      "\n",
      "UP_Paglicci_UP_Paglicci_12_Talus_Whole_XM_rescaled\n",
      "\n",
      "BE_111_Humerus_Prox_L_UnSeg_reoriented_sphereVOI_590_downscaled\n",
      "\n",
      "DPC_6139_z254_rescaled\n",
      "\n",
      "DM_278_Calcaneus_Right_UnSeg_downscaled\n",
      "\n",
      "NF_90_820715_Femur_Prox_R_UnSeg_reoriented_sphereVOI_2_downscaled\n",
      "\n",
      "M12_radius_xy_486\n",
      "\n",
      "Hydrochoerus_hydrochaeris_362243_Femur_Whole_xz409_downscaled\n",
      "\n",
      "DM_Calc_128_L_rescaled\n",
      "\n",
      "Dolichotis_patagonum_221358_Humerus_Whole_Slice1662_downscaled\n",
      "\n",
      "DM_302_568_Calcaneus_Whole_R0965\n",
      "\n",
      "Myocastor_coypus_221349_Humerus_Whole_MCSlice635\n",
      "\n",
      "BeliManastirG2Talus_YM\n",
      "\n",
      "Skull_1_y_407\n",
      "\n",
      "M12_radius_xy_486_rescaled\n",
      "\n",
      "KermK425AFemur_UnSeg_ZM\n",
      "\n",
      "Dart_Stw311Femur_Prox4_downscaled\n",
      "\n",
      "SK82_prox_fem_85kV_100uA_downscaled\n",
      "\n",
      "Hydrochoerus_hydrochaeris_155412_Femur_Whole_yz300_rescaled\n",
      "\n",
      "DM_278_Calcaneus_Right_UnSeg_rescaled\n",
      "\n",
      "KermK1088AHumerusL_UnSeg_YM_rescaled\n",
      "\n",
      "Propithecus_0546\n",
      "\n",
      "KermK425AFemur_UnSeg_ZM_rescaled\n",
      "\n",
      "Hydrochoerus_hydrochaeris_362243_Femur_Whole_xy1555_downscaled\n",
      "\n",
      "AF14501414FemurDistu_UnSeg_YM\n",
      "\n",
      "M17_femur_xy_1280_downscaled\n",
      "\n",
      "MCEU_1_3_64Femur_UnSeg_ZM_rescaled\n",
      "\n",
      "IlokKralievicaG24Talus_YM\n",
      "\n",
      "Dart_Stw311Femur_Prox4_rescaled\n",
      "\n",
      "Tamias_minimus_397142_Humerus_Whole_Slice542_rescaled\n",
      "\n",
      "AVO74_Hawk_headed_Parrot_x_758_downscaled\n",
      "\n",
      "NF_132_821042_Humerus_Prox_R_UnSeg_reoriented_sphereVOI_2_downscaled\n",
      "\n",
      "NF_33_819951_Talus_Whole_R1321\n",
      "\n",
      "BE_69_Humerus_Prox_R_UnSeg_X_786\n",
      "\n",
      "JMAF1272FemurU_UnSeg_ZM_rescaled\n",
      "\n",
      "KrapinaCSCAPHL_UnSeg_ZM\n",
      "\n",
      "UP_Paglicci_UP_Paglicci_12_ZM\n",
      "\n",
      "NF_90_820715_Femur_Prox_R_UnSeg_reoriented_sphereVOI_2\n",
      "\n",
      "Entraînement avec 279 images et validation avec 119 images.\n",
      "Nombre de patches générés : 312411 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 16:09:48.684 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\n.vanderesse\\AppData\\Local\\ia-sereos_env\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcul avec 47 coeur(s).\n",
      "Training data class percentages:          Air  Non-Bone      Bone\n",
      "0  0.822593  0.066911  0.110495\n"
     ]
    }
   ],
   "source": [
    "print(\"Finalize data\")\n",
    "data_path = unseg_dir\n",
    "if data_path in [None, \"None\", \".\"]:\n",
    "    print(\"Dataset path not defined\")\n",
    "elif unsegmented_imgs!=None and segmented_imgs!=None:\n",
    "    training_data_dir = unseg_dir.as_posix()\n",
    "    training_label_dir = label_dir.as_posix()\n",
    "    hdf5_name = str(data_path.joinpath(\"dataset.hdf5\").as_posix())\n",
    "    patches_name = str(data_path.joinpath(\"patches.csv\").as_posix())\n",
    "    val_name = str(data_path.joinpath(\"val.csv\").as_posix())\n",
    "    ratios_name = str(data_path.joinpath(\"ratios.csv\").as_posix())\n",
    "\n",
    "    class_num = 3 #Maybe more or less classes later.\n",
    "\n",
    "    print(f\"Répertoire des données d'entraînement: {training_data_dir}\")\n",
    "    print(f\"Répertoire des données labelisées d'entraînement: {training_label_dir}\")\n",
    "    print(f\"Répertoire des données labelisées d'entraînement: {hdf5_name}\")\n",
    "\n",
    "    \n",
    "    generate_hdf5(data_dir=unseg_dir, label_dir=label_dir, save_name=hdf5_name)\n",
    "    hdf5 = hdf5_name\n",
    "    print(hdf5_name)\n",
    "    stride = 32\n",
    "    train_size = 0.7\n",
    "    \n",
    "    output = 256\n",
    "    train_names, val_names = generate_patches(hdf5_file=hdf5_name, patches_csv=patches_name,\n",
    "                                                    validation_csv=val_name, train_ratio=train_size,\n",
    "                                                    stride=stride, output_size=output, always_train_csv=False)\n",
    "          \n",
    "    ratios_parallel = True\n",
    "\n",
    "    if ratios_parallel:\n",
    "        cpus_avail = list(range(cpu_count() + 1))\n",
    "        num_threads = cpu_count() - 1\n",
    "\n",
    "    start_multi = timer()\n",
    "    if ratios_parallel:\n",
    "        patches_df = _setup_patches(patches_csv=patches_name)\n",
    "        new_ratios = parallelize_ratios(df=patches_df, func=generate_ratios_streamlit_multi, hdf5_file=hdf5_name, class_num=3, n_cores=num_threads, to_streamlit=False)\n",
    "    else:\n",
    "        ratios = generate_ratios(hdf5_file=hdf5_name, patches_csv=patches_name, class_num=class_num)\n",
    "        new_ratios = pd.DataFrame(ratios)\n",
    "        ratio_headers = [f\"Class {idx}\" for idx in range(class_num)] #Just in case we do increase class numbers\n",
    "        new_ratios.columns = ratio_headers\n",
    "\n",
    "    class_means = pd.DataFrame(new_ratios.mean()).T\n",
    "    class_means.columns = [\"Air\", \"Non-Bone\", \"Bone\"]\n",
    "    print(\"Training data class percentages: \",class_means)\n",
    "    new_ratios.to_csv(f\"{ratios_name}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\n.vanderesse\\AppData\\Roaming\\Python\\Python310\\site-packages\\albumentations\\augmentations\\transforms.py:1284: FutureWarning: RandomContrast has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "C:\\Users\\n.vanderesse\\AppData\\Roaming\\Python\\Python310\\site-packages\\albumentations\\augmentations\\transforms.py:1258: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch progress:\n",
      "Progress training 60 epochs...\n",
      "Epoch 1 of 60\n",
      "There are 101459 bone and 27690 dirt patches in the training data...\n",
      "learning rate 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1/60:   0%|          | 0/120501 [00:00<?, ? batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image tensor([[[[0.1490, 0.1451, 0.1529,  ..., 0.1529, 0.1451, 0.1451],\n",
      "          [0.1569, 0.1490, 0.1529,  ..., 0.1529, 0.1412, 0.1490],\n",
      "          [0.1608, 0.1490, 0.1451,  ..., 0.1647, 0.1529, 0.1529],\n",
      "          ...,\n",
      "          [0.1686, 0.1804, 0.1647,  ..., 0.1451, 0.1412, 0.1608],\n",
      "          [0.1569, 0.1686, 0.1647,  ..., 0.1451, 0.1490, 0.1529],\n",
      "          [0.1608, 0.1686, 0.1686,  ..., 0.1529, 0.1569, 0.1608]]],\n",
      "\n",
      "\n",
      "        [[[0.7569, 0.7098, 0.6745,  ..., 0.8353, 0.8314, 0.8431],\n",
      "          [0.8000, 0.7608, 0.7137,  ..., 0.8275, 0.8431, 0.8510],\n",
      "          [0.8314, 0.8039, 0.7686,  ..., 0.8431, 0.8471, 0.8471],\n",
      "          ...,\n",
      "          [0.6863, 0.6980, 0.7333,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.6902, 0.7176, 0.7569,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7098, 0.7451, 0.7686,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0039, 0.0078,  ..., 0.0039, 0.0078, 0.0039],\n",
      "          [0.0000, 0.0039, 0.0039,  ..., 0.0039, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0039, 0.0039, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0039, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0392, 0.0549,  ..., 0.3373, 0.3608, 0.3608],\n",
      "          [0.0078, 0.0275, 0.0431,  ..., 0.3608, 0.3647, 0.3647],\n",
      "          [0.0471, 0.0667, 0.0471,  ..., 0.3490, 0.3373, 0.3373],\n",
      "          ...,\n",
      "          [0.1137, 0.1137, 0.1176,  ..., 0.1098, 0.0706, 0.0706],\n",
      "          [0.1216, 0.1059, 0.1098,  ..., 0.1137, 0.0784, 0.0784],\n",
      "          [0.1216, 0.1059, 0.1098,  ..., 0.1137, 0.0784, 0.0784]]],\n",
      "\n",
      "\n",
      "        [[[0.2078, 0.2078, 0.2078,  ..., 0.2078, 0.2118, 0.2078],\n",
      "          [0.2078, 0.2078, 0.2078,  ..., 0.1961, 0.2039, 0.2118],\n",
      "          [0.2078, 0.2078, 0.2039,  ..., 0.2000, 0.2039, 0.2118],\n",
      "          ...,\n",
      "          [0.2078, 0.2078, 0.2078,  ..., 0.2235, 0.2235, 0.2157],\n",
      "          [0.2039, 0.2118, 0.2118,  ..., 0.2196, 0.2118, 0.2078],\n",
      "          [0.2000, 0.2118, 0.2118,  ..., 0.2196, 0.2118, 0.2000]]]])\n",
      "mask tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 0.5020,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.5020, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5020, 1.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.5020,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.5020,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.5020,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.5020,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "          ...,\n",
      "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]]])\n",
      "pred tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5020, 0.5020],\n",
      "          [0.5020, 1.0000, 0.0000,  ..., 0.5020, 0.5020, 0.5020],\n",
      "          ...,\n",
      "          [0.0000, 1.0000, 0.0000,  ..., 0.5020, 0.5020, 1.0000],\n",
      "          [0.0000, 1.0000, 0.0000,  ..., 0.5020, 0.5020, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.5020, 0.0000, 0.5020,  ..., 0.0000, 0.5020, 0.5020],\n",
      "          [0.0000, 0.5020, 0.0000,  ..., 0.0000, 0.5020, 0.5020],\n",
      "          [0.5020, 0.5020, 0.0000,  ..., 0.5020, 0.5020, 0.5020],\n",
      "          ...,\n",
      "          [0.5020, 0.5020, 0.5020,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5020, 0.5020, 0.5020,  ..., 1.0000, 0.5020, 1.0000],\n",
      "          [0.0000, 0.5020, 0.5020,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.5020, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.5020, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 0.0000,  ..., 1.0000, 1.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.5020, 0.5020, 0.5020],\n",
      "          [0.0000, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "          ...,\n",
      "          [0.0000, 1.0000, 1.0000,  ..., 0.5020, 0.0000, 0.0000],\n",
      "          [1.0000, 1.0000, 0.0000,  ..., 0.0000, 0.5020, 0.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.0000, 1.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.5020,  ..., 0.5020, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5020, 0.5020],\n",
      "          [1.0000, 1.0000, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "          ...,\n",
      "          [0.0000, 1.0000, 1.0000,  ..., 1.0000, 0.5020, 0.5020],\n",
      "          [0.0000, 1.0000, 1.0000,  ..., 0.5020, 0.5020, 1.0000],\n",
      "          [0.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1/60:   1%|▏         | 1632/120501 [17:28<21:12:30,  1.56 batches/s, loss=0.72058195, loss1=505.30927, loss2=0.67005104] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 105\u001b[0m\n\u001b[0;32m     97\u001b[0m train_data_loader\u001b[39m.\u001b[39mappend(DataLoader(dataset\u001b[39m=\u001b[39mdata_set2,\n\u001b[0;32m     98\u001b[0m                                     batch_size\u001b[39m=\u001b[39mcurrent_batch,\n\u001b[0;32m     99\u001b[0m                                     shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    100\u001b[0m                                     num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[0;32m    103\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlearning rate \u001b[39m\u001b[39m{\u001b[39;00moptimizer\u001b[39m.\u001b[39mparam_groups[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.6f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m rdn_train(net, optimizer, train_data_loader, epoch\u001b[39m=\u001b[39;49mi_epoch,\n\u001b[0;32m    106\u001b[0m         total_epoch\u001b[39m=\u001b[39;49mEpoch, use_gpu\u001b[39m=\u001b[39;49muse_gpu, tensorboard_plot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    107\u001b[0m \u001b[39m#lr_scheduler.step()\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \n\u001b[0;32m    109\u001b[0m \u001b[39m# validating\u001b[39;00m\n\u001b[0;32m    110\u001b[0m val_loss, class_val \u001b[39m=\u001b[39m rdn_val(net, data_set1,\n\u001b[0;32m    111\u001b[0m                             use_gpu\u001b[39m=\u001b[39muse_gpu,\n\u001b[0;32m    112\u001b[0m                             i_epoch\u001b[39m=\u001b[39mi_epoch,\n\u001b[0;32m    113\u001b[0m                             class_num\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\n.vanderesse\\Desktop\\STAGE_Nolan\\Git\\IA-SeReOs\\RDN_segmentation_container\\MARS\\streamlit_apps\\utils\\train.py:59\u001b[0m, in \u001b[0;36mrdn_train\u001b[1;34m(net, optimizer, data_loader, epoch, total_epoch, use_gpu, tensorboard_plot)\u001b[0m\n\u001b[0;32m     56\u001b[0m     image2 \u001b[39m=\u001b[39m image2\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     58\u001b[0m \u001b[39m# # prediction\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m net(image2)\n\u001b[0;32m     61\u001b[0m loss1 \u001b[39m=\u001b[39m DomainEnrichLoss()(net, index)\n\u001b[0;32m     62\u001b[0m pred \u001b[39m=\u001b[39m net(image)\n",
      "File \u001b[1;32mc:\\Users\\n.vanderesse\\AppData\\Local\\ia-sereos_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\n.vanderesse\\Desktop\\STAGE_Nolan\\Git\\IA-SeReOs\\RDN_segmentation_container\\MARS\\streamlit_apps\\net\\unet_light_rdn.py:32\u001b[0m, in \u001b[0;36mUNet_Light_RDN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_rdn1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrdn1(x)\n\u001b[1;32m---> 32\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_rdn2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrdn2(x)\n\u001b[0;32m     34\u001b[0m     \u001b[39m# self.x_rdn2 = self.rdn2(self.x_rdn1)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     x1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minc(torch\u001b[39m.\u001b[39mcat((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_rdn2 ,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_rdn1), \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\n.vanderesse\\AppData\\Local\\ia-sereos_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\n.vanderesse\\Desktop\\STAGE_Nolan\\Git\\IA-SeReOs\\RDN_segmentation_container\\MARS\\streamlit_apps\\net\\domian_enrich_block.py:62\u001b[0m, in \u001b[0;36mDomainEnrich_Block.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     61\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbasic_block1(x)\n\u001b[1;32m---> 62\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbasic_block2(x)\n\u001b[0;32m     63\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\n.vanderesse\\AppData\\Local\\ia-sereos_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\n.vanderesse\\Desktop\\STAGE_Nolan\\Git\\IA-SeReOs\\RDN_segmentation_container\\MARS\\streamlit_apps\\net\\domian_enrich_block.py:44\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[0;32m     43\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(out)\n\u001b[1;32m---> 44\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn2(out)\n\u001b[0;32m     46\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m     identity \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample(x)\n",
      "File \u001b[1;32mc:\\Users\\n.vanderesse\\AppData\\Local\\ia-sereos_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\n.vanderesse\\AppData\\Local\\ia-sereos_env\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[0;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[0;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[0;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m    180\u001b[0m     bn_training,\n\u001b[0;32m    181\u001b[0m     exponential_average_factor,\n\u001b[0;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[0;32m    183\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\n.vanderesse\\AppData\\Local\\ia-sereos_env\\lib\\site-packages\\torch\\nn\\functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2447\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[0;32m   2448\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m-> 2450\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m   2451\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[0;32m   2452\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#Should probably move this up to the yaml section and put it into state\n",
    "\n",
    "n_channel = 1\n",
    "model_path = \"\"\n",
    "net = UNet_Light_RDN(n_channels=1, n_classes=3)\n",
    "if train_from_previous:              \n",
    "    if use_gpu:\n",
    "        net.load_state_dict(torch.load(model_path,\n",
    "                                    map_location=torch.device(type='cuda',\n",
    "                                                                index=use_gpu)))\n",
    "    else:\n",
    "        net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "\n",
    "if str(optimizer) == \"AdaBelief\":\n",
    "    optimizer = AdaBelief(net.parameters(),\n",
    "                        lr=float(learning_rate),\n",
    "                        eps=float(epsilon),\n",
    "                        betas=(0.9, 0.999),\n",
    "                        weight_decouple=True,\n",
    "                        rectify=False)\n",
    "else:\n",
    "    optimizer = getattr(optim,\n",
    "                        str(\"Adam\"))(net.parameters(),\n",
    "                                                    lr=learning_rate,\n",
    "                                                    weight_decay=weight_decay)\n",
    "    #learning rate schedule\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=period_size, gamma=0.1)\n",
    "\n",
    "\n",
    "\n",
    "# get training Epoch\n",
    "Epoch = epochs_num\n",
    "\n",
    "# load patches and ratios\n",
    "\n",
    "    # This gets used later to ramp up the amount of non-bone that is being thrown into the training.\n",
    "    # May have to think of a fancy way to get an equivelant number with Adabelief, but it is being set\n",
    "    # to the default Adam period for now.\n",
    "period = 8\n",
    "train_patches = get_patches(hdf5_file=hdf5_name, train_names=train_names, stride=stride, output_size=output)\n",
    "val_patches = get_patches(hdf5_file=hdf5_name, train_names=val_names, stride=stride, output_size=output)\n",
    "ratios = new_ratios\n",
    "\n",
    "# create train transform\n",
    "train_transform = transforms.Compose([dp.Augmentation(output_size=output),\n",
    "                                    dp.AdjustMask(class_num=3),\n",
    "                                    dp.Normalize(max=255, min=0),\n",
    "                                    dp.ToTensor()])\n",
    "val_transform = transforms.Compose([dp.AdjustMask(class_num=3),\n",
    "                                    dp.Normalize(max=255, min=0),\n",
    "                                    dp.ToTensor()])\n",
    "\n",
    "epoch_count = 0\n",
    "print(f\"Epoch progress:\")\n",
    "print(f\"Progress training {Epoch} epochs...\")\n",
    "total_timer = timer()\n",
    "iteration = 0\n",
    "for i_epoch in range(Epoch):\n",
    "    print(f\"Epoch {epoch_count + 1} of {Epoch}\")\n",
    "    if i_epoch < period:\n",
    "        dirt_rate = 0.5\n",
    "    elif i_epoch < 2 * period and i_epoch >= period:\n",
    "        dirt_rate = 0.3\n",
    "    elif i_epoch < 3 * period and i_epoch >= 2 * period:\n",
    "        dirt_rate = 0.1\n",
    "    else:\n",
    "        dirt_rate = 0.0\n",
    "\n",
    "    # Domain enrich patches\n",
    "    # Makes a decision about the lowest percent dirt that can be considered for the training.\n",
    "    new_patches = random_patches(dirt_choose_threshold=0.1, dirt_rate=dirt_rate,\n",
    "                                patches=train_patches, ratios=ratios)\n",
    "\n",
    "    rdn_patches, index = get_dirt_bone_patches(train_patches, ratios)\n",
    "\n",
    "    data_set1 = HDF52D(data_path.joinpath(\"dataset.hdf5\"), new_patches, val_patches,\n",
    "                    train_transform=train_transform,\n",
    "                    val_transform=val_transform)\n",
    "\n",
    "    data_set2 = HDF52D(data_path.joinpath(\"dataset.hdf5\"), rdn_patches, val_patches,\n",
    "                    train_transform=train_transform,\n",
    "                    val_transform=val_transform,\n",
    "                    train_idx=index)\n",
    "\n",
    "    train_data_loader = []\n",
    "\n",
    "    current_batch = int(batch_size)\n",
    "\n",
    "\n",
    "    train_data_loader.append(DataLoader(dataset=data_set1,\n",
    "                                        batch_size=current_batch,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=0))\n",
    "\n",
    "\n",
    "    train_data_loader.append(DataLoader(dataset=data_set2,\n",
    "                                        batch_size=current_batch,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=0))\n",
    "\n",
    "\n",
    "    print(f\"learning rate {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    rdn_train(net, optimizer, train_data_loader, epoch=i_epoch,\n",
    "            total_epoch=Epoch, use_gpu=use_gpu, tensorboard_plot=True)\n",
    "    #lr_scheduler.step()\n",
    "\n",
    "    # validating\n",
    "    val_loss, class_val = rdn_val(net, data_set1,\n",
    "                                use_gpu=use_gpu,\n",
    "                                i_epoch=i_epoch,\n",
    "                                class_num=3)\n",
    "\n",
    "    # save model\n",
    "    save_name = out_dir.joinpath(f\"Loss-{epoch_count}_{val_loss:.6f}.pth\")\n",
    "    torch.save(net.state_dict(), save_name)\n",
    "    class_val = pd.DataFrame(class_val)\n",
    "    class_val.columns = [\"Class Dice overlap\"]\n",
    "    epoch_count += 1\n",
    "    iteration = np.floor((100 * epoch_count) / int(Epoch))\n",
    "\n",
    "print('Training is finished !!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
